---
title: Optimising memory consumption of differential dataflow applications
author: Dr. Jan Pustelnik
author_title: Software Engineer at Actyx
author_url: https://github.com/gosubpl
author_image_url: /images/blog/jan-pustelnik.jpg
tags: [database, dashboards, reports]
---

In practical applications of differential dataflow to analysing factory event streams
one frequently encounters a lot of strings. Those strings usually represent various
names - of inventory articles, workstations or activities. They can also represent certain
properties of production processes, that we often call tags. A process can have certain
property or not, which we represent by a presence or absence of a certain tag.

Because of ownership structuring of differential dataflow we need to copy or clone a lot. 
This results often in a very high memory usage, that can be a limiting factor, especially in
memory constrained environments like the Raspberry Pi or other IoT platforms.
Once looking into the memory
usage statistics it is easy to see that most of this cloned content are strings.  
We can work around
this problem as long as we remember that Rust's `.clone()` operation is more about ownership than about copying bits.

Let's take a look how we have handled this problem in Actyx internal BI pipelines.

<!--truncate-->

:::note
See the [introduction to differential dataflow on developer.actyx.com] to get more context.
:::

[introduction to differential dataflow on developer.actyx.com]: https://developer.actyx.com/blog/2020/06/25/differential-dataflow/

## Problem setting

Let's assume that we need to process events describing finished goods produced at the factory. Each
finished goods item has following attributes: quantity of pieces produced (pcs),
article id (like `AGK75641`), human understandable article name like `Fork, Trifoil design line`,
workstation at which the good was reported (say `LATHE 3`) and order id (like `FG/1234567/2020`).
Let's model this as a Rust struct:

```
pub struct FinishedGoods {
	pub article_id: String,
	pub article_name: String,
	pub workstation: String,
	pub order_id: String,
	pub pcs: i64,
}
```

## ActyxOS approach

When working with ActyxOS, finished goods will probably come as a `payload` in an encompassing
`Event` data structure, which will look like that:


```
#[derive(Debug, Clone, Ord, PartialOrd, Eq, PartialEq, Abomonation)]
pub struct Event {
    timestamp: TimeStamp, // place first to sort in ascending (temporal) order
    lamport: LamportTimestamp, // place first to sort in ascending (causal) order
    payload: FinishedGoods, 
}

```

You might have noticed that for `Event` struct we derive some interesting attributes: `Eq`, `PartialEq`, `Ord`, `PartialOrd` and `Abomonation`. These
are here for a reason - `Eq`, `PartialEq`, `Ord` and `PartialOrd` are needed because differential dataflow orders (sorts) and deduplicates whatever data are flowing through
the pipelines. This is for a reason - imagine we had the following event structure (required derive clauses omitted for brevity):


```
pub enum ActivityStatus {
	Started,
	Stopped,
}

pub struct Activity {
	pub id: String,
	pub status: ActivityStatus,

pub struct ActivityEvent {
	timestamp: TimeStamp,
	payload: Activity,
}
```

Now, if we wanted to derive information about duration of the activity from the `ActivityEvent` we would want to have the events sorted,
for the `Activity::Stopped` to come after `Activity::Started` for a given `Activity::id`, to easily write a reducer. So the differential
dataflow makes the choice to sort by default using the order in which the fields are defined and their natural sorting order.

Now, in a true decentralised system, without a single coordinator, unfortunately, timestamps cannot be trusted to come in an order
consistent with how things "have happened". Imagine two devices on which the activity is being processed. A user first starts the activity
on the first device, then performs some work and marks completion by stopping the activity on the second device. If the clocks on those
devices are out of sync, not only the duration of the activity will be negative (like minus 2 hours), which is an unavoidable consequence
of wrong time on one or both of the devices, but also the `Started` coming after `Stopped` will result in activity incorrectly
recognised as `ongoing` instead of `completed`.

This is why in ActyxOS the default event ordering is by `LamportTimestamp`, which results in causal order, so a `Stopped` event will always
come after the `Started` event if they were generated by the same entity (fish), even if they were generated on different devices.
This is why, when processing those events,
in the differential dataflow, we also default to the same ordering. In the case of wrong time on devices, the worst consequence will
be incorrect duration, but not incorrect activity status. Therefore the following definition of `FinishedGoodsEvent` would most probably be
used in a real project involving ActyxOS:


```
#[derive(Debug, Clone, Ord, PartialOrd, Eq, PartialEq, Abomonation)]
pub struct FinishedGoodsEvent {
    lamport: LamportTimestamp, // place first to sort in ascending (causal) order
    payload: FinishedGoods, 
    timestamp: TimeStamp,
}
```

This brings us to the remaining atrribute: `Abomonation`. This one is required by the internal serialisation mechanism employed
by the differential dataflow, which is not `Serde` as most of the Rust code uses, but `Abomonation`. This is a very efficient binary wire
encoding, result in good performance of resultant program.

`Abomonation`, like `Serde` needs to be transitive, so the full definition of `FinishedGoods` would run like this: 
```
#[derive(Debug, Clone, Ord, PartialOrd, Eq, PartialEq, Abomonation)]
pub struct FinishedGoods {
	pub article_id: String,
	pub article_name: String,
	pub workstation: String,
	pub order_id: String,
	pub pcs: i64,
}
```

Now we are ready to write a pipeline that will produce a summary of produced pieces, aggregated by `workstation` and `article_id`.

The result will be the following `ProductionSummary` record:

```
#[derive(Clone, Debug, Ord, PartialOrd, Eq, PartialEq, Abomonation)]
pub struct ProductionSummary {
    pub article_id: String,
    pub article_name: String,
    pub workstation: String,
    pub total_pcs: i64,
}
```
that will be propagated to the database.


We start with extracting the essential parts of the event containing the `FinishedGoods` record:
```
let extracts = events.map(|ev| FinishedGoodsEvent {
    lamport: ev.lamport,
    payload: ev.payload,
    timestamp: ev.timestamp,
});
```

and then run the processing pipeline, which groups `pcs` by `article_id` and `workstation`
and calculates the `total_pcs`:

```
let out = extracts
    .group_by(|e| (e.payload.article_id.clone(), e.payload.workstation.clone())) // *
    .reduce(|(article_id, workstation), inputs, outputs| {
        // same article_id should mean same article_name
        let article_name = inputs                                 // 1
            .get(0)
            .map(|e| e.0.payload.article_name.clone())            // *
            .unwrap_or_default();
        let total_pcs: i64 = inputs
            .iter()
            // note we multiply by count below!
            .map(|(e, count)| *count as i64 * e.payload.pcs)      // 2
            .sum();
        outputs.push((
            ProductionSummary {
                article_id: article_id.clone(),                   // *
                article_name,
                workstation: workstation.clone(),                 // *
                total_pcs,
            },
            1,
        ));
    })
    .ungroup();
```

In the pipeline above we see a lot of `.clone()` operations applied to `String`s (lines indicated by a `*`). Given `article_id`
or `workstation` is cloned twice, which results in significant memory overhead, this pipepeline could be troublesome to deploy
for larger volumes of data in memory-constrained environments. However, before we show how to solve this issue, let's take
a step back - because there are two additional points to be made about the code above.

First ( `// 1` ) - our event design is not ideal, in each event
we have an `article_name` that should be the same for a given `article_id`. We have cleverly handled that, avoiding
copying all `article_name`'s, but still it perhaps would be better from a business perspective if there was a second
stream just mapping ids to names and we could use the result. Here, due to the duplication inherent in the event design,
we need to choose whether we run additional grouping by `process_name` or trust all `process_name`s for the same
`process_id` to be actually the same. One needs to be on the look out for such issues and frequently seemingly innocuous
design decisions about event schemas end up being problems down the analytics pipeline.

Second (`\\ 2`) - there is an important technicality about how differential dataflow works. If two successive records
in the pipeline have the same contents, they will be conflated together into one record with a count of `2`. So instead
of getting the following two records (where the second parameter in the tuple is the count):
```
(("article_1", 10), 1)
(("article_1", 10), 1)
```
we would get just one deduplicated record:
```
(("article_1", 10), 2)
```

Now let's get back to the main point about the memory usage due to excessive cloning.
Rust strings are modifiable, like in C++ and unlike their Java counterparts.
However, as C++ has departed from the copy-on-write (frequently abbreviated as CoW) approach for strings
due to the change in how processors are architected, similarly in Rust strings are not CoW by default.
That results in large memory usage occurring whenever we `.clone()` a string in Rust, because the contents
of the string get duplicated. However, as `.clone()` in Rust is about ownership semantics
more than actual copying of the information, this problem can be easily side-stepped.

## Optimising memory usage

The initial instinct would be to use the [`std::borrow::Cow`](https://doc.rust-lang.org/std/borrow/enum.Cow.html) , which
is a copy-on-mutation smart pointer in Rust and wrap the string inside of it like this:
```
use std::borrow::Cow;
let cow_string = Cow::from("some_article_id");
// and then at the end of the pipeline
let s: String = cow_string.to_string();
// or
let s_ref: &str = cow_string.as_ref();
// to get String you could also use:
cow_string.into_owned();
// or
cow_string.as_ref().to_owned();
```

With this approach, however, we encounter two important issues. First, `std::borrow::Cow` does not have an `Abomonation` instance. Second, even
if we wrote one, the solution would not be optimal. Imagine two events for `FinishedGoods`, both having the same `article_id`. They would
be deserialised into two different strings, having the same content. Only after that we would avoid the duplication in the pipeline by
using the CoW approach.

Because the strings in the analytics pipelines usually are not mutated, the ideal approach would be to use _string interning_ just like Java does.
That would leave out only a problem of creating a suitable `Abomonation` instance. This path was selected in `ActyxOS` SDK - and is called
[ArcVal](https://docs.rs/actyxos_sdk/0.4.0/actyxos_sdk/types/struct.ArcVal.html).

Using `ArcVal` requires importing it from `actyxos_sdk` crate:
```
use actyxos_sdk::types::ArcVal;
```

The data model definitions will look then as follows:
```
#[derive(Debug, Clone, Ord, PartialOrd, Eq, PartialEq, Serialize, Deserialize, Abomonation)]
pub struct FinishedGoods {
    pub article_id: ArcVal<str>,
    pub article_name: ArcVal<str>,
    pub workstation: ArcVal<str>,
    pub order_id: ArcVal<str>,
    pub pcs: i64,
}

#[derive(Clone, Debug, Ord, PartialOrd, Eq, PartialEq, Abomonation)]
pub struct ProductionSummary {
    pub article_id: ArcVal<str>,
    pub article_name: ArcVal<str>,
    pub workstation: ArcVal<str>,
    pub total_pcs: i64,
}
```

Note that the pipeline itself will not change at all! However, now all `.clone()` operations will be essentially free! In our experience, string
interning in the pipelines has usually reduced the memory usage to less than 50% of original usage (frequently even 30%, as would probably be for this pipeline).

## Summary

We have shown how to create a simple analytics pipeline with ActyxOS and optimise its memory usage using advanced features present in ActyxOS Rust SDK.
The whole code for the examples can be found in the [ActyxOS Dataflow repository](https://github.com/Actyx/actyxos_data_flow) under `examples/finished-goods-1`
and `examples/finished-goods-2`.
