# Artifact generation pipeline
#
# For general remarks, see ../README.md

schedules:
  - cron: "0 */6 * * *" # Every 6 hours
    displayName: Periodic build
    branches:
      include:
        - master

trigger: none

pr: none

variables:
  SLACK_HOOK: ***REMOVED***

stages:
  - stage: makeArtifacts
    dependsOn: []
    displayName: Make all artifacts
    pool:
      name: Native
    jobs:
      - job:
        displayName: make all-js
        steps:
          - bash: |
              build/bin/install-vault.sh
              make all-js
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)
          - publish: $(System.DefaultWorkingDirectory)/dist/js
            artifact: js-packages
            condition: succeeded()
      - job:
        displayName: make all-windows
        steps:
          - bash: |
              build/bin/install-vault.sh
              make all-windows
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)
          - publish: $(System.DefaultWorkingDirectory)/dist/bin
            artifact: windows-binaries
            condition: succeeded()
      - job: makeAllLinux
        displayName: make all-linux
        steps:
          - bash: |
              build/bin/install-vault.sh
              make all-linux
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)
          - publish: $(System.DefaultWorkingDirectory)/dist/bin
            artifact: linux-binaries
            condition: succeeded()
      - job:
        displayName: make docker-build-actyxos-
        strategy:
          matrix:
            x8664:
              ARCH: x86_64
            aarch64:
              ARCH: aarch64
            armv7:
              ARCH: armv7
            arm:
              ARCH: arm
        steps:
          - bash: |
              build/bin/install-vault.sh
              make docker-build-actyxos-$ARCH
              ./azure-pipelines/push-to-dockerhub.sh actyx/cosmos:actyxos-$ARCH
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)

      - job:
        displayName: make all-android
        steps:
          - bash: |
              build/bin/install-vault.sh
              make all-android
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)
          - publish: $(System.DefaultWorkingDirectory)/dist/bin
            artifact: android-binaries
            condition: succeeded()

  - stage: upload
    displayName: Upload to az blob store
    dependsOn:
      - makeArtifacts
    jobs:
      - job:
        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              path: pipeline-artifacts

          - task: AzureCLI@2
            # Now, there would be the nicely looking AzureFileCopy@4 task, which would use the `azcopy` cli (yes, it's not
            # included in `az`), to upload a bunch of files:
            # https://docs.microsoft.com/en-us/azure/devops/pipelines/tasks/deploy/azure-file-copy?view=azure-devops.
            #
            # Now, that task currently only works under Windows.
            # Next up: Directly use `azcopy`. No built-in authentication via azure pipelines, bummer.
            # Luckily, the `az` cli offers a legacy command `storage  blob upload-batch`.
            displayName: Upload
            inputs:
              azureSubscription: azure-ax-ci
              scriptType: bash
              scriptLocation: inlineScript
              inlineScript: |
                az --version
                az account show
                az storage blob upload-batch -s $(System.DefaultWorkingDirectory)/pipeline-artifacts -d https://axartifacts.blob.core.windows.net/artifacts/ --destination-path $(Build.SourceVersion)/

  - stage: notifyMakeSuccess
    displayName: Notify Slack on successful make all
    dependsOn:
      - upload
      - integration
      - release
    jobs:
      - template: jobs-notify-success.yml

  - stage: notifyMakeFailure
    displayName: Notify Slack on failure
    condition: failed()
    dependsOn:
      - makeArtifacts
      - upload
      - integration
      - release
    jobs:
      - template: slack-notify-failure.yml

  - stage: integration
    displayName: Nightly integration test
    pool:
      name: Native
    dependsOn:
      - upload
    jobs:
      - job: integrationTest
        displayName: Integration Test
        steps:
          - task: DownloadPipelineArtifact@2
            inputs:
              path: pipeline-artifacts
          - bash: |
              mkdir -p dist/bin 
              cd pipeline-artifacts
              for i in `ls`; do mv $i/* ../dist/bin/; done
              cd ../dist
              find -type f -exec chmod +x {} \;
              cp -r bin/linux-x86_64 bin/current
            displayName: Massage artifact directory structure
          - bash: |
              build/bin/install-vault.sh
              make prepare-js all-js
              cd integration
              source ~/.nvm/nvm.sh
              nvm use
              npm install
              npm test
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)
            displayName: npm test
          - publish: $(System.DefaultWorkingDirectory)/integration/logs
            condition: failed()
            artifact: integration-test-logs-attempt$(System.JobAttempt)
      - job: cleanup
        displayName: Integration test cleanup tasks
        condition: always()
        steps:
          - bash: |
              source ~/.nvm/nvm.sh
              cd integration
              nvm use
              npm install
              npm run cleanup 43200
            env:
              # Map secrets to env vars. This needs to be done manually
              AWS_ACCESS_KEY_ID: $(SECRET_AWS_ACCESS_KEY_ID)
              AWS_SECRET_ACCESS_KEY: $(SECRET_AWS_SECRET_ACCESS_KEY)
            name: cleanupInstances
            displayName: Clean up old integration test instances
  - stage: release
    displayName: Continuous release
    pool:
      name: Native
    dependsOn:
      - upload # If no artifacts have been built this shouldn't work
      - integration # Same if the integration tests didn't succeed
    jobs:
      - job: release
        displayName: Release
        condition: eq(variables['Build.SourceBranch'], 'refs/heads/master')
        steps:
          - checkout: self # self represents the repo where the initial Pipelines YAML file was found
            clean: true # whether to fetch clean each time
            submodules: recursive # set to 'true' for a single level of submodules or 'recursive' to get submodules of submodules
            persistCredentials: true # set to 'true' to leave the OAuth token in the Git config after the initial fetch
          - bash: |
              cd release
              source ~/.nvm/nvm.sh
              nvm use
              npm install
              echo "Building cosmos-release"
              npm run build
              echo "Running release"
              echo "Repo dir: $REPO_DIR"
              echo "Target rev: $TARGET_REV"
              echo "Setting git email and username"
              git config user.email "cosmos-release@actyx.io"
              git config user.name "cosmos-release"
              echo "Pruning local tags"
              git fetch --force --prune origin "+refs/tags/*:refs/tags/*"
              echo "Getting tags from remote"
              git fetch --all --tags
              npm run cli -- release 1 $TARGET_REV $ARM_NF --localRepo $REPO_DIR --skipMalformed --skipIfNoNotes
            env:
              ARM_NF: $(RELEASE_NETLIFY_ACCESS_TOKEN)
              REPO_DIR: $(Build.SourcesDirectory)
              TARGET_REV: $(Build.SourceVersion)
            displayName: run release
